{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import train_multi_rnn\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from spike_train_visual import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60  9 19 70 55 61 71 13 75 30 44 43 84 83 66 80 40 26  1 42 63 41 50 78 74\n",
      " 18 46 69  3 58  5 51 31 59 67  4 15 29 54 68 36 17 37 14 62  8 23 38 49 65\n",
      " 22 21 76  6 48 39  7 47 56 10 45 79 64 52 35 25 28  0 81 72 20 34 53 82 33\n",
      " 77 32 24 16 11 12 27 73  2 57]\n"
     ]
    }
   ],
   "source": [
    "#orders=np.arange(85)\n",
    "#np.random.shuffle(orders)\n",
    "#print ','.join(map(str,list(orders)))\n",
    "orders=np.array([60,9,19,70,55,61,71,13,75,30,44,43,84,83,66,80,40,26,1,42,63,41,50,78,74,18,46,69,3,58,5,51,31,59,67,4,15,29,54,68,36,17,37,14,62,8,23,38,49,65,22,21,76,6,48,39,7,47,56,10,45,79,64,52,35,25,28,0,81,72,20,34,53,82,33,77,32,24,16,11,12,27,73,2,57])\n",
    "print orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=np.genfromtxt('/home/honglei/projects/neural_network/data/small/truncated_23_0001.csv', delimiter=',')\n",
    "# #print data[0:5,orders]\n",
    "# #data[:,[6,12]]=data[:,[12,6]]\n",
    "# np.savetxt('/home/honglei/projects/neural_network/data/shuffle/truncated_23_0001.csv',data[:,orders],fmt='%d',delimiter=',')\n",
    "\n",
    "# data1=np.genfromtxt('/home/honglei/projects/neural_network/data/small/truncated_23_0001.csv', delimiter=',')\n",
    "# data2=np.genfromtxt('/home/honglei/projects/neural_network/data/shuffle/truncated_23_0001.csv', delimiter=',')\n",
    "# print np.linalg.norm(data1[:,orders]-data2)\n",
    "# print np.linalg.norm(data1[:,9]-data2[:,1])\n",
    "\n",
    "\n",
    "np.savetxt('/home/honglei/projects/neural_network/data/single_ch/6_alone.csv',data[:,12],fmt='%d',delimiter=',')\n",
    "\n",
    "# data=np.genfromtxt('/home/honglei/projects/neural_network/data/I1923_0001.csv', delimiter=',')\n",
    "# np.savetxt('/home/honglei/projects/neural_network/data/small1/truncated_23_0001.csv',data[0:10000,],fmt='%d',delimiter=',')\n",
    "# data=np.genfromtxt('/home/honglei/projects/neural_network/data/I1921_0001.csv', delimiter=',')\n",
    "# np.savetxt('/home/honglei/projects/neural_network/data/small1/truncated_21_0001.csv',data[0:10000,],fmt='%d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "(8000, 85)\n",
      "Building model\n",
      "False\n",
      "model/shared_variables/Cell0\n",
      "Training variables: [u'model/shuffle.csv/input_w:0', u'model/shared_variables/Cell0/Linear/Matrix:0', u'model/shared_variables/Cell0/Linear/Bias:0']\n",
      "True\n",
      "model/shared_variables/Cell0\n",
      "Training variables: [u'model/shuffle.csv/input_w:0', u'model/shared_variables/Cell0/Linear/Matrix:0', u'model/shared_variables/Cell0/Linear/Bias:0', u'model/truncated_23_0001.csv/input_w:0']\n",
      "Shared variables: [u'model/shared_variables/Cell0/Linear/Matrix:0', u'model/shared_variables/Cell0/Linear/Bias:0']\n",
      "Starting session\n",
      "model/shuffle.csv/input_w:0\n",
      "model/shared_variables/Cell0/Linear/Matrix:0\n",
      "model/shared_variables/Cell0/Linear/Bias:0\n",
      "model/shuffle.csv/model/shuffle.csv/input_w/RMSProp:0\n",
      "model/shuffle.csv/model/shuffle.csv/input_w/RMSProp_1:0\n",
      "model/shuffle.csv/model/shared_variables/Cell0/Linear/Matrix/RMSProp:0\n",
      "model/shuffle.csv/model/shared_variables/Cell0/Linear/Matrix/RMSProp_1:0\n",
      "model/shuffle.csv/model/shared_variables/Cell0/Linear/Bias/RMSProp:0\n",
      "model/shuffle.csv/model/shared_variables/Cell0/Linear/Bias/RMSProp_1:0\n",
      "model/truncated_23_0001.csv/input_w:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Cell0/Linear/Matrix/RMSProp:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Cell0/Linear/Matrix/RMSProp_1:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Cell0/Linear/Bias/RMSProp:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Cell0/Linear/Bias/RMSProp_1:0\n",
      "model/truncated_23_0001.csv/model/truncated_23_0001.csv/input_w/RMSProp:0\n",
      "model/truncated_23_0001.csv/model/truncated_23_0001.csv/input_w/RMSProp_1:0\n"
     ]
    }
   ],
   "source": [
    "train_multi_rnn.FLAGS.log_dir='/home/honglei/projects/neural_network/log_dir'\n",
    "m=train_multi_rnn.TrainMultiRNN('/home/honglei/projects/neural_network/data/shuffle_small//', fix_shared=False)\n",
    "#m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "(8000, 85)\n",
      "Building model\n",
      "False\n",
      "model/shared_variables/Cell0\n",
      "Training variables: [u'model/truncated_23_0001.csv/input_w:0']\n",
      "Shared variables: [u'model/shared_variables/Cell0/Linear/Matrix:0', u'model/shared_variables/Cell0/Linear/Bias:0']\n",
      "Starting session\n",
      "model/truncated_23_0001.csv/input_w:0\n",
      "model/shared_variables/Cell0/Linear/Matrix:0\n",
      "model/shared_variables/Cell0/Linear/Bias:0\n",
      "model/truncated_23_0001.csv/model/truncated_23_0001.csv/input_w/RMSProp:0\n",
      "model/truncated_23_0001.csv/model/truncated_23_0001.csv/input_w/RMSProp_1:0\n"
     ]
    }
   ],
   "source": [
    "train_multi_rnn.FLAGS.log_dir='/home/honglei/projects/neural_network/log_dir'\n",
    "m=train_multi_rnn.TrainMultiRNN('/home/honglei/projects/neural_network/data/shuffle', fix_shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.699 speed: 7 batches/sec\n",
      "8/80 loss: 0.695 speed: 12 batches/sec\n",
      "16/80 loss: 0.691 speed: 12 batches/sec\n",
      "24/80 loss: 0.684 speed: 13 batches/sec\n",
      "32/80 loss: 0.676 speed: 13 batches/sec\n",
      "40/80 loss: 0.665 speed: 13 batches/sec\n",
      "48/80 loss: 0.651 speed: 13 batches/sec\n",
      "56/80 loss: 0.634 speed: 13 batches/sec\n",
      "64/80 loss: 0.611 speed: 13 batches/sec\n",
      "72/80 loss: 0.586 speed: 13 batches/sec\n",
      "Epoch: 1 Train Loss: 0.564\n",
      "Epoch: 1 Train ROC-AUC: 0.516, PR-AUC: 0.003\n",
      "Saving latest results.\n",
      "Epoch: 1 Valid ROC-AUC: 0.550, PR-AUC: 0.004\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.285 speed: 14 batches/sec\n",
      "8/80 loss: 0.226 speed: 14 batches/sec\n",
      "16/80 loss: 0.196 speed: 13 batches/sec\n",
      "24/80 loss: 0.170 speed: 13 batches/sec\n",
      "32/80 loss: 0.146 speed: 13 batches/sec\n",
      "40/80 loss: 0.127 speed: 13 batches/sec\n",
      "48/80 loss: 0.113 speed: 13 batches/sec\n",
      "56/80 loss: 0.101 speed: 13 batches/sec\n",
      "64/80 loss: 0.091 speed: 13 batches/sec\n",
      "72/80 loss: 0.085 speed: 13 batches/sec\n",
      "Epoch: 2 Train Loss: 0.079\n",
      "Epoch: 2 Train ROC-AUC: 0.703, PR-AUC: 0.012\n",
      "Saving latest results.\n",
      "Epoch: 2 Valid ROC-AUC: 0.716, PR-AUC: 0.029\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.024 speed: 14 batches/sec\n",
      "8/80 loss: 0.015 speed: 13 batches/sec\n",
      "16/80 loss: 0.014 speed: 13 batches/sec\n",
      "24/80 loss: 0.016 speed: 13 batches/sec\n",
      "32/80 loss: 0.016 speed: 13 batches/sec\n",
      "40/80 loss: 0.014 speed: 13 batches/sec\n",
      "48/80 loss: 0.015 speed: 13 batches/sec\n",
      "56/80 loss: 0.015 speed: 13 batches/sec\n",
      "64/80 loss: 0.014 speed: 13 batches/sec\n",
      "72/80 loss: 0.015 speed: 13 batches/sec\n",
      "Epoch: 3 Train Loss: 0.015\n",
      "Epoch: 3 Train ROC-AUC: 0.890, PR-AUC: 0.030\n",
      "Saving latest results.\n",
      "Epoch: 3 Valid ROC-AUC: 0.864, PR-AUC: 0.029\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.021 speed: 14 batches/sec\n",
      "8/80 loss: 0.013 speed: 13 batches/sec\n",
      "16/80 loss: 0.011 speed: 13 batches/sec\n",
      "24/80 loss: 0.013 speed: 13 batches/sec\n",
      "32/80 loss: 0.014 speed: 13 batches/sec\n",
      "40/80 loss: 0.012 speed: 13 batches/sec\n",
      "48/80 loss: 0.013 speed: 13 batches/sec\n",
      "56/80 loss: 0.013 speed: 13 batches/sec\n",
      "64/80 loss: 0.012 speed: 13 batches/sec\n",
      "72/80 loss: 0.014 speed: 13 batches/sec\n",
      "Epoch: 4 Train Loss: 0.014\n",
      "Epoch: 4 Train ROC-AUC: 0.912, PR-AUC: 0.034\n",
      "Saving latest results.\n",
      "Epoch: 4 Valid ROC-AUC: 0.886, PR-AUC: 0.030\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.020 speed: 14 batches/sec\n",
      "8/80 loss: 0.012 speed: 13 batches/sec\n",
      "16/80 loss: 0.010 speed: 13 batches/sec\n",
      "24/80 loss: 0.013 speed: 13 batches/sec\n",
      "32/80 loss: 0.013 speed: 13 batches/sec\n",
      "40/80 loss: 0.012 speed: 13 batches/sec\n",
      "48/80 loss: 0.012 speed: 13 batches/sec\n",
      "56/80 loss: 0.013 speed: 13 batches/sec\n",
      "64/80 loss: 0.012 speed: 13 batches/sec\n",
      "72/80 loss: 0.013 speed: 13 batches/sec\n",
      "Epoch: 5 Train Loss: 0.013\n",
      "Epoch: 5 Train ROC-AUC: 0.925, PR-AUC: 0.044\n",
      "Saving latest results.\n",
      "Epoch: 5 Valid ROC-AUC: 0.892, PR-AUC: 0.038\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.021 speed: 14 batches/sec\n",
      "8/80 loss: 0.012 speed: 13 batches/sec\n",
      "16/80 loss: 0.010 speed: 13 batches/sec\n",
      "24/80 loss: 0.012 speed: 13 batches/sec\n",
      "32/80 loss: 0.013 speed: 13 batches/sec\n",
      "40/80 loss: 0.012 speed: 13 batches/sec\n",
      "48/80 loss: 0.012 speed: 13 batches/sec\n",
      "56/80 loss: 0.013 speed: 13 batches/sec\n",
      "64/80 loss: 0.012 speed: 13 batches/sec\n",
      "72/80 loss: 0.013 speed: 13 batches/sec\n",
      "Epoch: 6 Train Loss: 0.013\n",
      "Epoch: 6 Train ROC-AUC: 0.931, PR-AUC: 0.049\n",
      "Saving latest results.\n",
      "Epoch: 6 Valid ROC-AUC: 0.887, PR-AUC: 0.028\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.020 speed: 14 batches/sec\n",
      "8/80 loss: 0.012 speed: 13 batches/sec\n",
      "16/80 loss: 0.010 speed: 13 batches/sec\n",
      "24/80 loss: 0.012 speed: 13 batches/sec\n",
      "32/80 loss: 0.013 speed: 13 batches/sec\n",
      "40/80 loss: 0.011 speed: 13 batches/sec\n",
      "48/80 loss: 0.012 speed: 13 batches/sec\n",
      "56/80 loss: 0.012 speed: 13 batches/sec\n",
      "64/80 loss: 0.012 speed: 13 batches/sec\n",
      "72/80 loss: 0.013 speed: 13 batches/sec\n",
      "Epoch: 7 Train Loss: 0.013\n",
      "Epoch: 7 Train ROC-AUC: 0.936, PR-AUC: 0.054\n",
      "Saving latest results.\n",
      "Epoch: 7 Valid ROC-AUC: 0.883, PR-AUC: 0.029\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.020 speed: 14 batches/sec\n",
      "8/80 loss: 0.012 speed: 13 batches/sec\n",
      "16/80 loss: 0.010 speed: 13 batches/sec\n",
      "24/80 loss: 0.012 speed: 13 batches/sec\n",
      "32/80 loss: 0.013 speed: 13 batches/sec\n",
      "40/80 loss: 0.011 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.012 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "72/80 loss: 0.013 speed: 13 batches/sec\n",
      "Epoch: 8 Train Loss: 0.012\n",
      "Epoch: 8 Train ROC-AUC: 0.932, PR-AUC: 0.057\n",
      "Epoch: 8 Valid ROC-AUC: 0.868, PR-AUC: 0.030\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.020 speed: 14 batches/sec\n",
      "8/80 loss: 0.011 speed: 13 batches/sec\n",
      "16/80 loss: 0.010 speed: 13 batches/sec\n",
      "24/80 loss: 0.012 speed: 13 batches/sec\n",
      "32/80 loss: 0.012 speed: 13 batches/sec\n",
      "40/80 loss: 0.011 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.012 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "72/80 loss: 0.012 speed: 13 batches/sec\n",
      "Epoch: 9 Train Loss: 0.012\n",
      "Epoch: 9 Train ROC-AUC: 0.945, PR-AUC: 0.068\n",
      "Saving latest results.\n",
      "Epoch: 9 Valid ROC-AUC: 0.876, PR-AUC: 0.031\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.020 speed: 14 batches/sec\n",
      "8/80 loss: 0.011 speed: 13 batches/sec\n",
      "16/80 loss: 0.010 speed: 13 batches/sec\n",
      "24/80 loss: 0.012 speed: 13 batches/sec\n",
      "32/80 loss: 0.012 speed: 13 batches/sec\n",
      "40/80 loss: 0.011 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.012 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "72/80 loss: 0.012 speed: 13 batches/sec\n",
      "Epoch: 10 Train Loss: 0.012\n",
      "Epoch: 10 Train ROC-AUC: 0.948, PR-AUC: 0.071\n",
      "Saving latest results.\n",
      "Epoch: 10 Valid ROC-AUC: 0.876, PR-AUC: 0.027\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.019 speed: 14 batches/sec\n",
      "8/80 loss: 0.011 speed: 13 batches/sec\n",
      "16/80 loss: 0.009 speed: 13 batches/sec\n",
      "24/80 loss: 0.012 speed: 13 batches/sec\n",
      "32/80 loss: 0.012 speed: 13 batches/sec\n",
      "40/80 loss: 0.011 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.012 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "72/80 loss: 0.012 speed: 13 batches/sec\n",
      "Epoch: 11 Train Loss: 0.012\n",
      "Epoch: 11 Train ROC-AUC: 0.946, PR-AUC: 0.073\n",
      "Epoch: 11 Valid ROC-AUC: 0.871, PR-AUC: 0.022\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.020 speed: 14 batches/sec\n",
      "8/80 loss: 0.011 speed: 13 batches/sec\n",
      "16/80 loss: 0.009 speed: 13 batches/sec\n",
      "24/80 loss: 0.011 speed: 13 batches/sec\n",
      "32/80 loss: 0.012 speed: 13 batches/sec\n",
      "40/80 loss: 0.011 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.012 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "72/80 loss: 0.012 speed: 13 batches/sec\n",
      "Epoch: 12 Train Loss: 0.012\n",
      "Epoch: 12 Train ROC-AUC: 0.952, PR-AUC: 0.087\n",
      "Saving latest results.\n",
      "Epoch: 12 Valid ROC-AUC: 0.868, PR-AUC: 0.025\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.019 speed: 12 batches/sec\n",
      "8/80 loss: 0.011 speed: 12 batches/sec\n",
      "16/80 loss: 0.009 speed: 13 batches/sec\n",
      "24/80 loss: 0.011 speed: 13 batches/sec\n",
      "32/80 loss: 0.012 speed: 13 batches/sec\n",
      "40/80 loss: 0.011 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.011 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "72/80 loss: 0.012 speed: 13 batches/sec\n",
      "Epoch: 13 Train Loss: 0.012\n",
      "Epoch: 13 Train ROC-AUC: 0.955, PR-AUC: 0.085\n",
      "Saving latest results.\n",
      "Epoch: 13 Valid ROC-AUC: 0.867, PR-AUC: 0.028\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.018 speed: 14 batches/sec\n",
      "8/80 loss: 0.011 speed: 13 batches/sec\n",
      "16/80 loss: 0.009 speed: 13 batches/sec\n",
      "24/80 loss: 0.011 speed: 13 batches/sec\n",
      "32/80 loss: 0.012 speed: 13 batches/sec\n",
      "40/80 loss: 0.010 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.011 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "72/80 loss: 0.012 speed: 13 batches/sec\n",
      "Epoch: 14 Train Loss: 0.012\n",
      "Epoch: 14 Train ROC-AUC: 0.954, PR-AUC: 0.090\n",
      "Epoch: 14 Valid ROC-AUC: 0.869, PR-AUC: 0.026\n",
      "8000\n",
      "100\n",
      "80\n",
      "0/80 loss: 0.018 speed: 13 batches/sec\n",
      "8/80 loss: 0.011 speed: 13 batches/sec\n",
      "16/80 loss: 0.009 speed: 13 batches/sec\n",
      "24/80 loss: 0.011 speed: 13 batches/sec\n",
      "32/80 loss: 0.012 speed: 13 batches/sec\n",
      "40/80 loss: 0.010 speed: 13 batches/sec\n",
      "48/80 loss: 0.011 speed: 13 batches/sec\n",
      "56/80 loss: 0.011 speed: 13 batches/sec\n",
      "64/80 loss: 0.011 speed: 13 batches/sec\n",
      "WARNING: User interrupted program.\n",
      "Do you want to save the latest data? [y/n]n\n",
      "Results deleted.\n"
     ]
    }
   ],
   "source": [
    "m.partially_train('/home/honglei/projects/neural_network/log_dir/test_small.ckt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189.01253, 189.10707, 186.18031, 188.3015, 185.95229, 186.07175, 187.41185, 189.49435, 190.12299, 187.86702, 185.88139, 184.6797, 185.27435, 188.62473, 186.93918, 187.25377, 191.1053, 184.9077, 188.96356, 190.37833, 187.09399, 189.00517, 185.9955, 185.22289, 183.06477, 188.20303, 187.5865, 188.41893, 185.93799, 186.86914, 185.96077, 188.03783, 185.57463, 185.58244, 186.73927, 185.82025, 187.6485, 188.54814, 187.71747, 184.41495, 185.69759, 189.38234, 186.68858, 184.88885, 186.71269, 188.66484, 185.88707, 188.01375, 186.65341, 187.98712]\n"
     ]
    }
   ],
   "source": [
    "m.restore('/home/honglei/projects/neural_network/log_dir/test_small.ckt')\n",
    "origin_inputw=m.get_value_of_variable('model/truncated_23_0001.csv/input_w:0')\n",
    "m.restore('/home/honglei/projects/neural_network/log_dir/test_shuffle.ckt')\n",
    "shuffle_inputw=m.get_value_of_variable('model/truncated_23_0001.csv/input_w:0')\n",
    "d2=[]\n",
    "for i in range(50):\n",
    "    rand_orders=np.arange(85)\n",
    "    np.random.shuffle(rand_orders)\n",
    "    rand_inputw=shuffle_inputw[rand_orders,:]\n",
    "    d2.append(np.linalg.norm(origin_inputw-rand_inputw))\n",
    "print d2\n",
    "d1=[np.linalg.norm(origin_inputw-shuffle_inputw)]*len(d2)\n",
    "d3=[np.linalg.norm(origin_inputw[orders,:]-shuffle_inputw)]*len(d2)\n",
    "plt.boxplot([d1,d2,d3],0,'')\n",
    "plt.xticks([1,2,3], ['w1-w2', 'w1-shuffled_w2','w1-reordered_w2'])\n",
    "plt.ylabel('L2 norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903.273516373\n"
     ]
    }
   ],
   "source": [
    "m.restore('/home/honglei/projects/neural_network/log_dir/test_shuffle_small.ckt')\n",
    "origin_inputw=m.get_value_of_variable('model/truncated_23_0001.csv/input_w:0')\n",
    "shuffle_inputw=m.get_value_of_variable('model/shuffle.csv/input_w:0')\n",
    "# d2=[]\n",
    "# for i in range(50):\n",
    "#     rand_orders=np.arange(85)\n",
    "#     np.random.shuffle(rand_orders)\n",
    "#     rand_inputw=shuffle_inputw[rand_orders,:]\n",
    "#     d2.append(np.linalg.norm(origin_inputw-rand_inputw))\n",
    "# print d2\n",
    "# d1=[np.linalg.norm(origin_inputw-shuffle_inputw)]*len(d2)\n",
    "# d3=[np.linalg.norm(origin_inputw[orders,:]-shuffle_inputw)]*len(d2)\n",
    "# plt.boxplot([d1,d2,d3],0,'')\n",
    "# plt.xticks([1,2,3], ['w1-w2', 'w1-shuffled_w2','w1-reordered_w2'])\n",
    "# plt.ylabel('L2 norm')\n",
    "# plt.show()\n",
    "\n",
    "data1=np.genfromtxt('/home/honglei/projects/neural_network/data/shuffle_small//truncated_23_0001.csv', delimiter=',')\n",
    "data2=np.genfromtxt('/home/honglei/projects/neural_network/data/shuffle_small/shuffle.csv', delimiter=',')\n",
    "\n",
    "rep_data1=np.dot(data1,origin_inputw)\n",
    "rep_data2=np.dot(data2,shuffle_inputw)\n",
    "print np.linalg.norm(rep_data1-rep_data2)\n",
    "visualSeries(rep_data1)\n",
    "visualSeries(rep_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109.65516248\n"
     ]
    }
   ],
   "source": [
    "m.restore('/home/honglei/projects/neural_network/log_dir/test_two_small.ckt')\n",
    "inputw1=m.get_value_of_variable('model/truncated_23_0001.csv/input_w:0')\n",
    "inputw2=m.get_value_of_variable('model/truncated_21_0001.csv/input_w:0')\n",
    "data1=np.genfromtxt('/home/honglei/projects/neural_network/data/small1/truncated_23_0001.csv', delimiter=',')\n",
    "data2=np.genfromtxt('/home/honglei/projects/neural_network/data/small1/truncated_21_0001.csv', delimiter=',')\n",
    "\n",
    "rep_data1=np.dot(data1,inputw1)\n",
    "rep_data2=np.dot(data2,inputw2)\n",
    "\n",
    "#print np.linalg.norm(data1-data2)\n",
    "print np.linalg.norm(rep_data1-rep_data2)\n",
    "visualSeries(data1)\n",
    "visualSeries(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "(8000, 85)\n",
      "Building model\n",
      "Training variables: [u'model/shuffle.csv/Layer1/weights:0', u'model/shared_variables/Layer2/weights:0', u'model/shared_variables/Layer2/bias:0']\n",
      "Training variables: [u'model/shuffle.csv/Layer1/weights:0', u'model/shared_variables/Layer2/weights:0', u'model/shared_variables/Layer2/bias:0', u'model/truncated_23_0001.csv/Layer1/weights:0']\n",
      "Shared variables: [u'model/shared_variables/Layer2/weights:0', u'model/shared_variables/Layer2/bias:0']\n",
      "Starting session\n",
      "model/shuffle.csv/Layer1/weights:0\n",
      "model/shared_variables/Layer2/weights:0\n",
      "model/shared_variables/Layer2/bias:0\n",
      "model/shuffle.csv/model/shuffle.csv/Layer1/weights/RMSProp:0\n",
      "model/shuffle.csv/model/shuffle.csv/Layer1/weights/RMSProp_1:0\n",
      "model/shuffle.csv/model/shared_variables/Layer2/weights/RMSProp:0\n",
      "model/shuffle.csv/model/shared_variables/Layer2/weights/RMSProp_1:0\n",
      "model/shuffle.csv/model/shared_variables/Layer2/bias/RMSProp:0\n",
      "model/shuffle.csv/model/shared_variables/Layer2/bias/RMSProp_1:0\n",
      "model/truncated_23_0001.csv/Layer1/weights:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Layer2/weights/RMSProp:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Layer2/weights/RMSProp_1:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Layer2/bias/RMSProp:0\n",
      "model/truncated_23_0001.csv/model/shared_variables/Layer2/bias/RMSProp_1:0\n",
      "model/truncated_23_0001.csv/model/truncated_23_0001.csv/Layer1/weights/RMSProp:0\n",
      "model/truncated_23_0001.csv/model/truncated_23_0001.csv/Layer1/weights/RMSProp_1:0\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import train_multi_fcnet\n",
    "\n",
    "train_multi_fcnet.FLAGS.log_dir='/home/honglei/projects/neural_network/log_dir'\n",
    "m=train_multi_fcnet.TrainMultiFCNet('/home/honglei/projects/neural_network/data/shuffle_small/', fix_shared=False)\n",
    "#m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120.48477, 120.91798, 120.91375, 120.66364, 120.56027, 120.44719, 119.93005, 120.56586, 120.1909, 120.61044, 120.16321, 120.75238, 120.73853, 120.33401, 120.59312, 120.66002, 120.09286, 120.44724, 119.72305, 119.68443, 120.0192, 120.33186, 120.55452, 120.34799, 119.57524, 120.29719, 119.6647, 120.32313, 120.37698, 120.76255, 120.32048, 120.09824, 119.69699, 120.46315, 120.78207, 120.43684, 120.16575, 119.87554, 119.9917, 120.5054, 120.62099, 119.19208, 119.86597, 119.56715, 120.46431, 120.2859, 120.36205, 120.1976, 119.80991, 120.40553]\n"
     ]
    }
   ],
   "source": [
    "m.restore('/home/honglei/projects/neural_network/log_dir/fcnet_small_shuffle.ckt')\n",
    "origin_inputw=m.get_value_of_variable('model/truncated_23_0001.csv/Layer1/weights:0')\n",
    "shuffle_inputw=m.get_value_of_variable('model/shuffle.csv/Layer1/weights:0')\n",
    "d2=[]\n",
    "for i in range(50):\n",
    "    rand_orders=np.arange(85)\n",
    "    np.random.shuffle(rand_orders)\n",
    "    rand_inputw=shuffle_inputw[rand_orders,:]\n",
    "    d2.append(np.linalg.norm(origin_inputw-rand_inputw))\n",
    "print d2\n",
    "d1=[np.linalg.norm(origin_inputw-shuffle_inputw)]*len(d2)\n",
    "d3=[np.linalg.norm(origin_inputw[orders,:]-shuffle_inputw)]*len(d2)\n",
    "plt.boxplot([d1,d2,d3],0,'')\n",
    "plt.xticks([1,2,3], ['w1-w2', 'w1-shuffled_w2','w1-reordered_w2'])\n",
    "plt.ylabel('L2 norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#m.restore('/home/honglei/projects/neural_network/log_dir/best.ckt')\n",
    "X_list, predict_list=m.get_train_data()\n",
    "X=X_list[1]\n",
    "predicts=predict_list[1]\n",
    "overlayPredicts(X,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.895, PR-AUC: 0.115\n",
      "Valid ROC-AUC: 0.734, PR-AUC: 0.015\n",
      "Test ROC-AUC: 0.744, PR-AUC: 0.013\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score(X.flatten(),predicts.flatten())\n",
    "m.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
